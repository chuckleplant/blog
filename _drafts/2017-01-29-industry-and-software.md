---
layout: post
title: "Software's backstory"
date: 2017-01-29
---

##Methodical selection

Software development has too many edges and it's a completely different thing for two slightly different companies. If you have two companies making a similar program, the methodology might be completely different. Even if a single company is making two different programs, the methodology might not be the same.

As it happens with programming languages, there isn't one that fits all needs. In some cases you have to choose; and sometimes your choice does not matter at all as long as the thing works. You get to know a programming language a lot better once you know how compilers work, this is what I'm trying to do with methodologies. Consider this as an introspection of my somewhat limited experience.

In order to understand the nature of software development, what helped me was a comparison between software products and hardware products. Hardware products are old, and it's to be expected that with the years comes knowledge and expertise. Software is new, but spreads quickly. If evolution tell us something about this is that we'll have some weird mutants before we can have a well defined specimen.

##What you see is what you get

Early on, people tried to apply hardware production chains to software. It was the most intuitive and logical way to do things. For hardware it's actually the only way it can work, each step needs the previous one. This very production method has been working for ages and for very different products.

* Have an idea
* Analyse what it solves
* Design the product
* Build the product
* See if it works
* Sell it

Sounds familiar? 

Behold the [waterfall software model](https://en.wikipedia.org/wiki/Waterfall_model). This is the one I learnt during my years in university. I actually thought that's how all companies would be making software, because why would you not?

##Big fish

Giants in the industry are by definition the leading force. In the early years those were the ones making hardware. Therefore, they were the ones with means (money) to start making software. It's a no brainer, they applied the methodology they knew to the products they didn't. 

And it worked! The waterfall methodology is a solid solution, easy to relate to for the stakeholders. It is comfortable for them because they get a sense of the stage production is currently in. This methodology was the cornerstone of software development. 

##The artist

Ask Apple who's more important when making the iPhone, is it the designers from California, or the assemblers from China?

Now ask the same question for a software product. Is the architect's job more important than the programmer's? I think this used to be the case. Programmers were understood as the workforce, the ones hitting the nails with a hammer.

Now, it's hard to tell, in many cases it's the same person and those are just two of his roles. I remember during university wondering whether I wanted to be a programmer, the hardworking guy writing elegant and efficient code; or the architect/designer, wrapping my head around high level understanding of the program and the patterns applicable. 

Later on I just thought of my job as *developer*, the guy doing software development whatever it takes. And I believe that's what these roles have turned into. 


##A new contender

Maybe you know about how big old companies make software, but you sure have heard how the big **new** companies are making it. 

##Aftermath

The thing is it works. I can't say the waterfall methodology is not a good one. 
